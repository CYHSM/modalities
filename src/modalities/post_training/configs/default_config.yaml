# Model Configuration
model:
  model_path: "/raid/s3/opengptx/mfrey/3.73T-Tokens/checkpoints/aug15_tokfix"
  model_type: "custom_gpt2"
  torch_dtype: "bfloat16"
  trust_remote_code: true
  use_flash_attention: true
  gradient_checkpointing: true

# Data Configuration
data:
  # Multiple datasets with weights and filters
  datasets:
    - name: "teknium/OpenHermes-2.5"
      split: "train"
      weight: 0.3
      filters:
        min_instruction_tokens: 10
        max_instruction_tokens: 256
        min_response_tokens: 50
        max_response_tokens: 1024
        min_total_tokens: 100
        max_total_tokens: 1280
        
    - name: "vicgalle/alpaca-gpt4"
      split: "train"
      weight: 0.2
      filters:
        min_instruction_tokens: 10
        max_instruction_tokens: 200
        min_response_tokens: 30
        max_response_tokens: 800
        
    - name: "GAIR/lima"
      split: "train"
      weight: 0.15
      filters:
        min_instruction_tokens: 20
        max_instruction_tokens: 512
        min_response_tokens: 100
        max_response_tokens: 2048
        
    - name: "databricks/databricks-dolly-15k"
      split: "train"
      weight: 0.2
      filters:
        min_instruction_tokens: 15
        max_instruction_tokens: 256
        min_response_tokens: 50
        max_response_tokens: 1024
        
    - name: "Open-Orca/OpenOrca"
      split: "train[:100000]"  # Take subset
      weight: 0.15
      filters:
        min_instruction_tokens: 10
        max_instruction_tokens: 300
        min_response_tokens: 30
        max_response_tokens: 1024
  
  # Global data settings
  max_samples_per_dataset: 50000
  shuffle_buffer: 10000
  preprocessing_num_workers: 16
  
  # Quality filters
  quality_filters:
    remove_code_heavy: false  # Remove samples with >50% code
    remove_math_heavy: false  # Remove samples with >30% math
    min_alphabetic_ratio: 0.7  # At least 70% alphabetic chars
    max_repetition_ratio: 0.3  # Max 30% repeated n-grams
    diversity_sampling: true  # Sample diverse instructions
    
  # Prompt configuration
  prompt:
    use_system_prompt: true
    system_prompt: "You are a helpful AI assistant."
    template_style: "chatml"  # Options: chatml, alpaca, vicuna, llama2, plain
    add_eos_token: true
    padding_side: "left"
    max_length: 2048
    
# Training Configuration
training:
  output_dir: "/raid/s3/opengptx/mfrey/3.73T-Tokens/finetuned"
  num_train_epochs: 3
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 8
  gradient_checkpointing: true
  
  # Optimizer settings
  learning_rate: 0.00001
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.03
  weight_decay: 0.01
  max_grad_norm: 1.0
  optim: "adamw_torch"
  
  # Training strategy
  fp16: false
  bf16: true
  tf32: true  # Enable TF32 on Ampere GPUs
  
  # Efficiency settings
  dataloader_num_workers: 8
  dataloader_pin_memory: true
  remove_unused_columns: true
  
  # Saving and evaluation
  save_strategy: "steps"
  save_steps: 500
  save_total_limit: 3
  evaluation_strategy: "steps"
  eval_steps: 500
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  load_best_model_at_end: true
  
  # Advanced settings
  ddp_find_unused_parameters: false
  ddp_bucket_cap_mb: 25
  full_determinism: false
  seed: 42
  
  # DeepSpeed configuration (optional)
  deepspeed: null  # Set to path of DS config if needed
  
# Evaluation Configuration
evaluation:
  benchmarks:
    - name: "mmlu"
      num_shots: 5
      batch_size: 8
    - name: "hellaswag"
      num_shots: 0
      batch_size: 32
    - name: "arc_easy"
      num_shots: 0
      batch_size: 32
    - name: "arc_challenge"
      num_shots: 25
      batch_size: 8
    - name: "truthfulqa"
      num_shots: 0
      batch_size: 32
    - name: "gsm8k"
      num_shots: 5
      batch_size: 8
    - name: "winogrande"
      num_shots: 5
      batch_size: 16
      
  eval_during_training: true
  eval_steps: 1000
  save_eval_results: true
  
# Weights & Biases Configuration
wandb:
  project: "8b-instruction-tuning"
  entity: null  # Your WandB entity
  name: null  # Auto-generated if null
  tags: ["instruction-tuning", "8B"]
  group: "experiment_1"
  notes: "Full fine-tuning of 3.73T tokens on 8B model"
  log_model: true
  log_metrics: true
  log_eval_predictions: false  # Set true to log sample predictions
  
# Multi-GPU Configuration
distributed:
  strategy: "fsdp"  # Options: ddp, fsdp, deepspeed
  fsdp_config:
    sharding_strategy: "FULL_SHARD"
    cpu_offload: false
    mixed_precision: true
    backward_prefetch: true
    forward_prefetch: true
    use_orig_params: true